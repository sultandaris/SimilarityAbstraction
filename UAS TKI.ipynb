{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e31064b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SASTRAWI STEMMER\n",
      "file Docs1.txt:\n",
      "Penyakit jantung merupakan\n",
      "\n",
      "file Docs2.txt:\n",
      "Perkembangan industri video\n",
      "\n",
      "file Docs3.txt:\n",
      "Sulitnya penyedia layanan\n",
      "\n",
      "file Docs4.txt:\n",
      "Sulitnya penyedia layanan\n",
      "\n",
      "Preprocessing file: Docs1.txt\n",
      "Original words: 265\n",
      "After preprocessing: 193\n",
      "After stemming: 193\n",
      "Unique words: 97\n",
      "Saved to: preprocessed_Docs1.txt\n",
      "\n",
      "\n",
      "Preprocessing file: Docs2.txt\n",
      "Original words: 152\n",
      "After preprocessing: 122\n",
      "After stemming: 122\n",
      "Unique words: 70\n",
      "Saved to: preprocessed_Docs2.txt\n",
      "\n",
      "\n",
      "Preprocessing file: Docs3.txt\n",
      "Original words: 174\n",
      "After preprocessing: 141\n",
      "After stemming: 141\n",
      "Unique words: 90\n",
      "Saved to: preprocessed_Docs3.txt\n",
      "\n",
      "\n",
      "Preprocessing file: Docs4.txt\n",
      "Original words: 174\n",
      "After preprocessing: 141\n",
      "After stemming: 141\n",
      "Unique words: 90\n",
      "Saved to: preprocessed_Docs4.txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "print(\"SASTRAWI STEMMER\")\n",
    "\n",
    "folder_path = r\"C:\\Users\\Sultan Daris\\Downloads\\UAS TKI Projek\\DokumenAbstrak\\Dokumen\" \n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            words = content.split()\n",
    "            first_10_words = ' '.join(words[:3])\n",
    "            print(f\"file {filename}:\\n{first_10_words}\\n\")\n",
    "\n",
    "processed_documents_sastrawi = {}\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    print(f\"Preprocessing file: {filename}\")\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "                    \n",
    "            content = content.lower()\n",
    "            \n",
    "            sentences = re.split(r'[.!?]+', content)\n",
    "            \n",
    "            content = re.sub(r'[^\\w\\s]', ' ', content)\n",
    "            \n",
    "            content = re.sub(r'\\s+', ' ', content).strip()\n",
    "            \n",
    "            words = content.split()\n",
    "            \n",
    "            stop_words = {'dan', 'atau', 'yang', 'adalah', 'ini', 'itu', 'dengan', 'untuk', 'pada', 'dalam', 'dari', 'ke', 'di', 'akan', 'dapat', 'juga', 'tidak', 'ada', 'satu', 'dua', 'tiga'}\n",
    "            filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "            \n",
    "            stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "            \n",
    "            processed_documents_sastrawi[filename] = stemmed_words\n",
    "            \n",
    "            segmented_lines = []\n",
    "            for i in range(0, len(stemmed_words), 7):\n",
    "                line = ' '.join(stemmed_words[i:i+7])\n",
    "                segmented_lines.append(line)\n",
    "            \n",
    "            segmented_output = '\\n'.join(segmented_lines)\n",
    "            \n",
    "            output_filename = f\"preprocessed_{filename}\"\n",
    "            output_path = os.path.join(r\"C:\\Users\\Sultan Daris\\Downloads\\UAS TKI Projek\\DokumenAbstrak\\DokumenSastrawi\", output_filename)\n",
    "            with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(segmented_output)\n",
    "            \n",
    "           \n",
    "            print(f\"Original words: {len(words)}\")\n",
    "            print(f\"After preprocessing: {len(filtered_words)}\")\n",
    "            print(f\"After stemming: {len(stemmed_words)}\")\n",
    "            unique_words = len(set(stemmed_words))\n",
    "            print(f\"Unique words: {unique_words}\")\n",
    "            print(f\"Saved to: {output_filename}\")\n",
    "            print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef08b098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PORTER STEMMER\n",
      "Preprocessing file: Docs1.txt\n",
      "Original words: 265\n",
      "After preprocessing: 193\n",
      "After Porter stemming: 193\n",
      "Unique words: 104\n",
      "Saved to: preprocessed_Docs1.txt\n",
      "\n",
      "\n",
      "Preprocessing file: Docs2.txt\n",
      "Original words: 152\n",
      "After preprocessing: 122\n",
      "After Porter stemming: 122\n",
      "Unique words: 76\n",
      "Saved to: preprocessed_Docs2.txt\n",
      "\n",
      "\n",
      "Preprocessing file: Docs3.txt\n",
      "Original words: 174\n",
      "After preprocessing: 141\n",
      "After Porter stemming: 141\n",
      "Unique words: 95\n",
      "Saved to: preprocessed_Docs3.txt\n",
      "\n",
      "\n",
      "Preprocessing file: Docs4.txt\n",
      "Original words: 174\n",
      "After preprocessing: 141\n",
      "After Porter stemming: 141\n",
      "Unique words: 95\n",
      "Saved to: preprocessed_Docs4.txt\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "print(\"PORTER STEMMER\")\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "processed_documents_porter = {}\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    print(f\"Preprocessing file: {filename}\")\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "                    \n",
    "            content = content.lower()\n",
    "            \n",
    "            sentences = re.split(r'[.!?]+', content)\n",
    "            \n",
    "            content = re.sub(r'[^\\w\\s]', ' ', content)\n",
    "            \n",
    "            content = re.sub(r'\\s+', ' ', content).strip()\n",
    "            \n",
    "            words = content.split()\n",
    "            \n",
    "            stop_words = {'dan', 'atau', 'yang', 'adalah', 'ini', 'itu', 'dengan', 'untuk', 'pada', 'dalam', 'dari', 'ke', 'di', 'akan', 'dapat', 'juga', 'tidak', 'ada', 'satu', 'dua', 'tiga'}\n",
    "            filtered_words = [word for word in words if word not in stop_words and len(word) > 2]\n",
    "            \n",
    "            stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "            \n",
    "            processed_documents_porter[filename] = stemmed_words\n",
    "            \n",
    "            segmented_lines = []\n",
    "            for i in range(0, len(stemmed_words), 7):\n",
    "                line = ' '.join(stemmed_words[i:i+7])\n",
    "                segmented_lines.append(line)\n",
    "            \n",
    "            segmented_output = '\\n'.join(segmented_lines)\n",
    "            \n",
    "            output_filename = f\"preprocessed_{filename}\"\n",
    "            output_path = os.path.join(r\"C:\\Users\\Sultan Daris\\Downloads\\UAS TKI Projek\\DokumenAbstrak\\DokumenPorter\", output_filename)\n",
    "            with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "                output_file.write(segmented_output)\n",
    "            \n",
    "            print(f\"Original words: {len(words)}\")\n",
    "            print(f\"After preprocessing: {len(filtered_words)}\")\n",
    "            print(f\"After Porter stemming: {len(stemmed_words)}\")\n",
    "            unique_words = len(set(stemmed_words))\n",
    "            print(f\"Unique words: {unique_words}\")\n",
    "            print(f\"Saved to: {output_filename}\")\n",
    "            print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c991dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score (Sastrawi) antara Docs1.txt and Docs2.txt: 0.6044\n",
      "Similarity Score (Sastrawi) antara Docs1.txt and Docs3.txt: 0.6064\n",
      "Similarity Score (Sastrawi) antara Docs1.txt and Docs4.txt: 0.6064\n",
      "Similarity Score (Sastrawi) antara Docs2.txt and Docs3.txt: 0.4574\n",
      "Similarity Score (Sastrawi) antara Docs2.txt and Docs4.txt: 0.4574\n",
      "Similarity Score (Sastrawi) antara Docs3.txt and Docs4.txt: 1.0000\n",
      "\n",
      "\n",
      "Similarity Score (Porter) antara Docs1.txt and Docs2.txt: 0.6105\n",
      "Similarity Score (Porter) antara Docs1.txt and Docs3.txt: 0.6344\n",
      "Similarity Score (Porter) antara Docs1.txt and Docs4.txt: 0.6344\n",
      "Similarity Score (Porter) antara Docs2.txt and Docs3.txt: 0.5543\n",
      "Similarity Score (Porter) antara Docs2.txt and Docs4.txt: 0.5543\n",
      "Similarity Score (Porter) antara Docs3.txt and Docs4.txt: 1.0000\n",
      "\n",
      "\n",
      "=== SASTRAWI vs PORTER STEMMING ===\n",
      "\n",
      "SASTRAWI STEMMING:\n",
      "Mean similarity score for Docs1.txt: 0.6057\n",
      "Mean similarity score for Docs2.txt: 0.5064\n",
      "Mean similarity score for Docs3.txt: 0.6879\n",
      "Mean similarity score for Docs4.txt: 0.6879\n",
      "\n",
      "PORTER STEMMING:\n",
      "similarity score untuk Docs1.txt: 0.6264\n",
      "similarity score untuk Docs2.txt: 0.5731\n",
      "similarity score untuk Docs3.txt: 0.7296\n",
      "similarity score untuk Docs4.txt: 0.7296\n",
      "\n",
      "PERBANDINGAN:\n",
      "Document     Sastrawi   Porter     Difference\n",
      "---------------------------------------------\n",
      "Docs1.txt    0.6057     0.6264     0.0207    \n",
      "Docs2.txt    0.5064     0.5731     0.0666    \n",
      "Docs3.txt    0.6879     0.7296     0.0416    \n",
      "Docs4.txt    0.6879     0.7296     0.0416    \n"
     ]
    }
   ],
   "source": [
    "def rabin_karp_ngrams(words, n, base=256, mod=101):\n",
    "    hashes = set()\n",
    "    if len(words) < n:\n",
    "        return hashes\n",
    "    h = 0\n",
    "    high_order = pow(base, n-1, mod)\n",
    "    \n",
    "    for i in range(n):\n",
    "        h = (h * base + ord(words[i][0])) % mod\n",
    "    hashes.add(h)\n",
    "\n",
    "    for i in range(1, len(words) - n + 1):\n",
    "        h = (h - ord(words[i-1][0]) * high_order) % mod\n",
    "        h = (h * base + ord(words[i+n-1][0])) % mod\n",
    "        hashes.add(h)\n",
    "    return hashes\n",
    "\n",
    "doc_scores_sastrawi = {doc: [] for doc in processed_documents_sastrawi}\n",
    "doc_names_sastrawi = list(processed_documents_sastrawi.keys())\n",
    "ngram_hashes_sastrawi = {doc: rabin_karp_ngrams(processed_documents_sastrawi[doc], n=3) for doc in doc_names_sastrawi}\n",
    "\n",
    "doc_scores_porter = {doc: [] for doc in processed_documents_porter}\n",
    "doc_names_porter = list(processed_documents_porter.keys())\n",
    "ngram_hashes_porter = {doc: rabin_karp_ngrams(processed_documents_porter[doc], n=3) for doc in doc_names_porter}\n",
    "\n",
    "for i in range(len(doc_names_sastrawi)):\n",
    "    for j in range(i+1, len(doc_names_sastrawi)):\n",
    "        doc1, doc2 = doc_names_sastrawi[i], doc_names_sastrawi[j]\n",
    "        common = ngram_hashes_sastrawi[doc1] & ngram_hashes_sastrawi[doc2]\n",
    "        total = ngram_hashes_sastrawi[doc1] | ngram_hashes_sastrawi[doc2]\n",
    "        similarity = len(common) / len(total) if total else 0\n",
    "        doc_scores_sastrawi[doc1].append(similarity)\n",
    "        doc_scores_sastrawi[doc2].append(similarity)\n",
    "        print(f\"Similarity Score (Sastrawi) antara {doc1} and {doc2}: {similarity:.4f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(doc_names_porter)):\n",
    "    for j in range(i+1, len(doc_names_porter)):\n",
    "        doc1, doc2 = doc_names_porter[i], doc_names_porter[j]\n",
    "        common = ngram_hashes_porter[doc1] & ngram_hashes_porter[doc2]\n",
    "        total = ngram_hashes_porter[doc1] | ngram_hashes_porter[doc2]\n",
    "        similarity = len(common) / len(total) if total else 0\n",
    "        doc_scores_porter[doc1].append(similarity)\n",
    "        doc_scores_porter[doc2].append(similarity)\n",
    "        print(f\"Similarity Score (Porter) antara {doc1} and {doc2}: {similarity:.4f}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"=== SASTRAWI vs PORTER STEMMING ===\\n\")\n",
    "\n",
    "print(\"SASTRAWI STEMMING:\")\n",
    "for doc, scores in doc_scores_sastrawi.items():\n",
    "    mean_score = sum(scores) / len(scores) if scores else 0\n",
    "    print(f\"Mean similarity score for {doc}: {mean_score:.4f}\")\n",
    "\n",
    "print(\"\\nPORTER STEMMING:\")\n",
    "for doc, scores in doc_scores_porter.items():\n",
    "    mean_score = sum(scores) / len(scores) if scores else 0\n",
    "    print(f\"similarity score untuk {doc}: {mean_score:.4f}\")\n",
    "\n",
    "print(\"\\nPERBANDINGAN:\")\n",
    "print(f\"{'Document':<12} {'Sastrawi':<10} {'Porter':<10} {'Difference':<10}\")\n",
    "print(\"-\" * 45)\n",
    "for doc in doc_names_sastrawi:\n",
    "    sastrawi_score = sum(doc_scores_sastrawi[doc]) / len(doc_scores_sastrawi[doc]) if doc_scores_sastrawi[doc] else 0\n",
    "    porter_score = sum(doc_scores_porter[doc]) / len(doc_scores_porter[doc]) if doc_scores_porter[doc] else 0\n",
    "    difference = abs(sastrawi_score - porter_score)\n",
    "    print(f\"{doc:<12} {sastrawi_score:<10.4f} {porter_score:<10.4f} {difference:<10.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
