{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2223f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc_id_query                                            abstrak\n",
      "0             1  Masalah stunting di Indonesia merupakan ancama...\n",
      "1             2  Systemic Lupus Erytemathosus (SLE) merupakan p...\n",
      "2             3  Emosi merupakan respons reflektif dari pengala...\n",
      "3             4  Pemberian kredit adalah salah satu layanan uta...\n",
      "4             5  Advertorial terselubung atau unlabeled adverto...\n",
      "5             6  Diabetes melitus (DM) atau diabetes adalah pen...\n",
      "6             7  Seleksi Nasional Berdasarkan Tes (SNBT) merupa...\n",
      "7             8  Gangguan penglihatan memiliki prevalensi yang ...\n",
      "8             9  Pengendalian persediaan merupakan faktor penti...\n",
      "9            10  Deepfake adalah teknologi yang menggunakan kec...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "df = pd.read_csv('dataset.csv')\n",
    "query = pd.concat([df.iloc[:, 0], df.iloc[:, 2]], axis=1)\n",
    "gold_standard = pd.concat([df.iloc[:, 0], df.iloc[:, 3]], axis=1)\n",
    "\n",
    "print(query)\n",
    "\n",
    "corpus = pd.read_csv('corpus.csv')\n",
    "corpus = pd.concat([corpus.iloc[:, 0], corpus.iloc[:, 2]], axis=1)\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 2]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "corpus['abstrak'] = corpus.iloc[:, 1].apply(preprocess_text)\n",
    "query['abstrak'] = query.iloc[:, 1].apply(preprocess_text)\n",
    "\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "def stem_text(text):\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "corpus['abstrak_sastrawi'] = corpus['abstrak'].apply(stem_text)\n",
    "query['abstrak_sastrawi'] = query['abstrak'].apply(stem_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e34556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def porter_stem_text(text):\n",
    "    tokens = text.split()\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "corpus['abstrak_porter'] = corpus['abstrak'].apply(porter_stem_text)\n",
    "query['abstrak_porter'] = query['abstrak'].apply(porter_stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19f4e39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    doc_id                                            abstrak  \\\n",
      "0        1  persebaran uang palsu melibatkan fenomena mara...   \n",
      "1        2  bank pembiayaan rakyat syariah bprs bakti makm...   \n",
      "2        3  2024 menempati peringkat keenam media sosial i...   \n",
      "3        4  listrik salah kebutuhan dasar apapun timbul li...   \n",
      "4        5  revolusi industri dampak perkembangan teknolog...   \n",
      "..     ...                                                ...   \n",
      "85      86  turnover keluarnya karyawan organisasi tempatn...   \n",
      "86      87  industri perikanan memiliki peran strategis ke...   \n",
      "87      88  kepuasan pelanggan salah elemen menjalankan us...   \n",
      "88      89  diabetes mellitus penyakit menahun mengganggu ...   \n",
      "89      90  kebijakan pembelajaran tatap muka ptm diluncur...   \n",
      "\n",
      "                                     abstrak_sastrawi  \\\n",
      "0   sebar uang palsu libat fenomena marak indonesi...   \n",
      "1   bank biaya rakyat syariah bprs bakti makmur in...   \n",
      "2   2024 tempat peringkat enam media sosial indone...   \n",
      "3   listrik salah butuh dasar apa timbul listrik p...   \n",
      "4   revolusi industri dampak kembang teknologi gun...   \n",
      "..                                                ...   \n",
      "85  turnover keluar karyawan organisasi tempat div...   \n",
      "86  industri ikan milik peran strategis tahan pang...   \n",
      "87  puas langgan salah elemen jalan usaha restoran...   \n",
      "88  diabetes mellitus sakit tahun ganggu metabolis...   \n",
      "89  bijak ajar tatap muka ptm luncur perintah pand...   \n",
      "\n",
      "                                       abstrak_porter  \n",
      "0   persebaran uang palsu melibatkan fenomena mara...  \n",
      "1   bank pembiayaan rakyat syariah bpr bakti makmu...  \n",
      "2   2024 menempati peringkat keenam media sosial i...  \n",
      "3   listrik salah kebutuhan dasar apapun timbul li...  \n",
      "4   revolusi industri dampak perkembangan teknolog...  \n",
      "..                                                ...  \n",
      "85  turnov keluarnya karyawan organisasi tempatnya...  \n",
      "86  industri perikanan memiliki peran strategi ket...  \n",
      "87  kepuasan pelanggan salah elemen menjalankan us...  \n",
      "88  diabet mellitu penyakit menahun mengganggu met...  \n",
      "89  kebijakan pembelajaran tatap muka ptm diluncur...  \n",
      "\n",
      "[90 rows x 4 columns]\n",
      "   doc_id_query                                            abstrak  \\\n",
      "0             1  stunting indonesia ancaman serius penanganan s...   \n",
      "1             2  systemic lupus erytemathosus sle penyakit auto...   \n",
      "2             3  emosi respons reflektif pengalaman manusia ran...   \n",
      "3             4  pemberian kredit salah layanan utama ditawarka...   \n",
      "4             5  advertorial terselubung unlabeled advertorial ...   \n",
      "5             6  diabetes melitus diabetes penyakit kelainan me...   \n",
      "6             7  seleksi nasional berdasarkan tes snbt penentu ...   \n",
      "7             8  gangguan penglihatan memiliki prevalensi masya...   \n",
      "8             9  pengendalian persediaan faktor beroperasinya p...   \n",
      "9            10  deepfake teknologi kecerdasan buatan memanipul...   \n",
      "\n",
      "                                    abstrak_sastrawi  \\\n",
      "0  stunting indonesia ancam serius tangan stuntin...   \n",
      "1  systemic lupus erytemathosus sle sakit autoimu...   \n",
      "2  emosi respons reflektif alam manusia rangsang ...   \n",
      "3  beri kredit salah layan utama tawar bank dukun...   \n",
      "4  advertorial selubung unlabeled advertorial pra...   \n",
      "5  diabetes melitus diabetes sakit lain metabolis...   \n",
      "6  seleksi nasional dasar tes snbt tentu krusial ...   \n",
      "7  ganggu lihat milik prevalensi masyarakat salah...   \n",
      "8  kendali sedia faktor operasi usaha pengaruh la...   \n",
      "9  deepfake teknologi cerdas buat manipulasi gamb...   \n",
      "\n",
      "                                      abstrak_porter  \n",
      "0  stunt indonesia ancaman seriu penanganan stunt...  \n",
      "1  system lupu erytemathosu sle penyakit autoimun...  \n",
      "2  emosi respon reflektif pengalaman manusia rang...  \n",
      "3  pemberian kredit salah layanan utama ditawarka...  \n",
      "4  advertori terselubung unlabel advertori prakti...  \n",
      "5  diabet melitu diabet penyakit kelainan metabol...  \n",
      "6  seleksi nasion berdasarkan te snbt penentu kru...  \n",
      "7  gangguan penglihatan memiliki prevalensi masya...  \n",
      "8  pengendalian persediaan faktor beroperasinya p...  \n",
      "9  deepfak teknolog kecerdasan buatan memanipulas...  \n",
      "   doc_id_query dokumen_yang_mirip\n",
      "0             1             41, 31\n",
      "1             2     44, 47, 61, 87\n",
      "2             3             21, 23\n",
      "3             4              2, 10\n",
      "4             5                 71\n",
      "5             6                 89\n",
      "6             7                 74\n",
      "7             8     62, 67, 76, 85\n",
      "8             9                 na\n",
      "9            10                 29\n"
     ]
    }
   ],
   "source": [
    "print(corpus)\n",
    "print(query)\n",
    "print(gold_standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12cc4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rabin_karp_ngrams(tokens, n):\n",
    "    if len(tokens) < n:\n",
    "        return set()\n",
    "    \n",
    "    ngrams = set()\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = tuple(tokens[i:i+n])\n",
    "        ngrams.add(ngram)\n",
    "    \n",
    "    return ngrams\n",
    "\n",
    "processed_documents_sastrawi = {}\n",
    "processed_documents_porter = {}\n",
    "\n",
    "for _, row in corpus.iterrows():\n",
    "    doc_id = row['doc_id']\n",
    "    processed_documents_sastrawi[doc_id] = row['abstrak_sastrawi'].split()\n",
    "    processed_documents_porter[doc_id] = row['abstrak_porter'].split()\n",
    "    def calculate_query_similarity(query_text, processed_documents, n_gram_size=3):\n",
    "        query_ngrams = rabin_karp_ngrams(query_text.split(), n_gram_size)\n",
    "        similarities = []\n",
    "        \n",
    "        for doc_id, doc_words in processed_documents.items():\n",
    "            doc_ngrams = rabin_karp_ngrams(doc_words, n_gram_size)\n",
    "            common = query_ngrams & doc_ngrams\n",
    "            union = query_ngrams | doc_ngrams\n",
    "            # Use Dice coefficient: 2 * |intersection| / (|A| + |B|)\n",
    "            dice_coefficient = (2 * len(common)) / (len(query_ngrams) + len(doc_ngrams)) if (len(query_ngrams) + len(doc_ngrams)) > 0 else 0.0\n",
    "            dice_coefficient = round(dice_coefficient, 4)  # Round to 4 decimal places\n",
    "            \n",
    "            if dice_coefficient > 0:\n",
    "                # Only include documents with a non-zero similarity score\n",
    "                doc_id = int(doc_id)\n",
    "                similarities.append((doc_id, dice_coefficient))\n",
    "        \n",
    "        return sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "query_similarities_sastrawi = []\n",
    "for _, query_row in query.iterrows():\n",
    "    query_id = query_row['doc_id_query']\n",
    "    query_text = query_row['abstrak_sastrawi']\n",
    "    similarities = calculate_query_similarity(query_text, processed_documents_sastrawi)\n",
    "    query_similarities_sastrawi.append({\n",
    "        'query_id': query_id,\n",
    "        'similarities': similarities\n",
    "    })\n",
    "\n",
    "query_similarities_porter = []\n",
    "for _, query_row in query.iterrows():\n",
    "    query_id = query_row['doc_id_query']\n",
    "    query_text = query_row['abstrak_porter']\n",
    "    similarities = calculate_query_similarity(query_text, processed_documents_porter)\n",
    "    query_similarities_porter.append({\n",
    "        'query_id': query_id,\n",
    "        'similarities': similarities\n",
    "    })\n",
    "\n",
    "combined_results = []\n",
    "\n",
    "for sastrawi_result, porter_result in zip(query_similarities_sastrawi, query_similarities_porter):\n",
    "    query_id = sastrawi_result['query_id']  # atau porter_result['query_id'], sama saja\n",
    "    porter_sims = ', '.join([f\"({doc_id})\" for doc_id, score in porter_result['similarities']])\n",
    "    sastrawi_sims = ', '.join([f\"({doc_id})\" for doc_id, score in sastrawi_result['similarities']])\n",
    "    \n",
    "    combined_results.append({\n",
    "        'id_kueri': query_id,\n",
    "        'rk_porter': porter_sims,\n",
    "        'rk_sastrawi': sastrawi_sims\n",
    "    })\n",
    "\n",
    "rk_porter_results = []\n",
    "for result in query_similarities_porter:\n",
    "    query_id = result['query_id']\n",
    "    for doc_id, similarity in result['similarities']:\n",
    "        rk_porter_results.append({\n",
    "            'query_id': query_id,\n",
    "            'doc_id': doc_id,\n",
    "            'similarity': similarity\n",
    "        })\n",
    "\n",
    "rk_sastrawi_results = []\n",
    "for result in query_similarities_sastrawi:\n",
    "    query_id = result['query_id']\n",
    "    for doc_id, similarity in result['similarities']:\n",
    "        rk_sastrawi_results.append({\n",
    "            'query_id': query_id,\n",
    "            'doc_id': doc_id,\n",
    "            'similarity': similarity\n",
    "        })\n",
    "\n",
    "rk_porter_df = pd.DataFrame(rk_porter_results)\n",
    "rk_sastrawi_df = pd.DataFrame(rk_sastrawi_results)\n",
    "similarity_table = pd.DataFrame(combined_results)\n",
    "similarity_table['expert'] = gold_standard['dokumen_yang_mirip'].tolist()\n",
    "\n",
    "with pd.ExcelWriter('similarity_results.xlsx', engine='openpyxl') as writer:\n",
    "    similarity_table.to_excel(writer, sheet_name='Results RK', index=False)\n",
    "    rk_porter_df.to_excel(writer, sheet_name='RK Porter Detailed', index=False)\n",
    "    rk_sastrawi_df.to_excel(writer, sheet_name='RK Sastrawi Detailed', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29a18101",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_similarities_sastrawi_cosine = []\n",
    "for _, query_row in query.iterrows():\n",
    "    query_id = query_row['doc_id_query']\n",
    "    query_text = query_row['abstrak_sastrawi']\n",
    "    similarities = calculate_query_similarity(query_text, processed_documents_sastrawi)\n",
    "    query_similarities_sastrawi_cosine.append({\n",
    "        'query_id': query_id,\n",
    "        'similarities': similarities\n",
    "    })\n",
    "\n",
    "query_similarities_porter_cosine = []\n",
    "for _, query_row in query.iterrows():\n",
    "    query_id = query_row['doc_id_query']\n",
    "    query_text = query_row['abstrak_porter']\n",
    "    similarities = calculate_query_similarity(query_text, processed_documents_porter)\n",
    "    query_similarities_porter_cosine.append({\n",
    "        'query_id': query_id,\n",
    "        'similarities': similarities\n",
    "    })\n",
    "\n",
    "combined_results_cosine = []\n",
    "\n",
    "for sastrawi_result, porter_result in zip(query_similarities_sastrawi_cosine, query_similarities_porter_cosine):\n",
    "    query_id = sastrawi_result['query_id']\n",
    "    porter_sims = ', '.join([f\"({doc_id})\" for doc_id, score in porter_result['similarities']])\n",
    "    sastrawi_sims = ', '.join([f\"({doc_id})\" for doc_id, score in sastrawi_result['similarities']])\n",
    "    \n",
    "    combined_results_cosine.append({\n",
    "        'id_kueri': query_id,\n",
    "        'rk_porter_cosine': porter_sims,\n",
    "        'rk_sastrawi_cosine': sastrawi_sims\n",
    "    })\n",
    "\n",
    "rk_porter_results_cosine = []\n",
    "for result in query_similarities_porter_cosine:\n",
    "    query_id = result['query_id']\n",
    "    for doc_id, similarity in result['similarities']:\n",
    "        rk_porter_results_cosine.append({\n",
    "            'query_id': query_id,\n",
    "            'doc_id': doc_id,\n",
    "            'similarity': similarity\n",
    "        })\n",
    "\n",
    "rk_sastrawi_results_cosine = []\n",
    "for result in query_similarities_sastrawi_cosine:\n",
    "    query_id = result['query_id']\n",
    "    for doc_id, similarity in result['similarities']:\n",
    "        rk_sastrawi_results_cosine.append({\n",
    "            'query_id': query_id,\n",
    "            'doc_id': doc_id,\n",
    "            'similarity': similarity\n",
    "        })\n",
    "\n",
    "rk_porter_cosine_df = pd.DataFrame(rk_porter_results_cosine)\n",
    "rk_sastrawi_cosine_df = pd.DataFrame(rk_sastrawi_results_cosine)\n",
    "similarity_table_cosine = pd.DataFrame(combined_results_cosine)\n",
    "similarity_table_cosine['expert'] = gold_standard['dokumen_yang_mirip'].tolist()\n",
    "\n",
    "with pd.ExcelWriter('Cosine_similarity_results.xlsx', engine='openpyxl') as writer:\n",
    "    similarity_table_cosine.to_excel(writer, sheet_name='Results Cosine', index=False)\n",
    "    rk_porter_cosine_df.to_excel(writer, sheet_name='Porter Cosine Detailed', index=False)\n",
    "    rk_sastrawi_cosine_df.to_excel(writer, sheet_name='Sastrawi Cosine Detailed', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
